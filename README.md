# Data Engineer

### <img align="center" src="assets/mortarboard.png" alt="santhoshguntupalli" height="50" width="60" /> Education
Master's in Management Information Systems

### <img align="center" src="assets/tool-box.png" alt="santhoshguntupalli" height="50" width="60" /> Skillset
## Programming Languages/Frameworks <img align="center" src="assets/programming.png" alt="santhoshguntupalli" height="30" width="40" />:
Python, Java, JavaScript, C, C#, C++, Scala, R, Shell Scripting, Golang

### Cloud Technologies <img align="center" src="assets/cloud.png" alt="santhoshguntupalli" height="30" width="40" />:
AWS, GCP, Azure, Snowflake, Oracle, Docker, Kubernetes

### Big Data and Data Engineering Tools/Services <img align="center" src="assets/big-data.png" alt="santhoshguntupalli" height="30" width="40" />:
Spark, Kafka, Hadoop, Hive, Airflow, HBase, Nifi, Teradata, Amazon RedShift, MapReduce, Flume, Flink, Informatica, Talend, AWS Glue, Amazon S3, Databricks, Azure Data Factory (ADF), Synapse Analytics, Trifacta, JSON, Avro, Parquet, ORC, XML, Protobuf, ELK Stack, PostgreSQL, MongoDB, Google BigQuery, Elasticsearch, HDFS, Metastore

### Machine Learning<img align="center" src="assets/machine-learning.png" alt="santhoshguntupalli" height="30" width="40" />:
TensorFlow, PyTorch, scikit-learn, PySpark, NLTK, LLMâ€™s 

### DevOps, Monitoring, and Other Tools/Services <img align="center" src="assets/tool-box.png" alt="santhoshguntupalli" height="30" width="40" />:
Jenkins, JIRA, Confluence, Tableau, Power BI, GitHub, Git, RESTful, Splunk, Prometheus, PowerShell, Linux, UI/UX, Bash, Pub/Sub, Jupyter Notebooks, PyCharm.</strong></p>

### <img align="center" src="assets/project-management.png" alt="santhoshguntupalli" height="50" width="60" /> Projects

# [Movie Recommendation Engine]( https://mrs-sg-bfc2e6fa78db.herokuapp.com/)

<img align="center" src="assets/MRS Sample.png" alt="santhoshguntupalli" height="200" width="400" />

Created a Movie Recommendation System that suggests films based on a chosen movie selection.

Skills: Machine Learning, Natural Language Processing (NLP), Python Programming, Feature Engineering, Recommendation Systems. Data Pre-processing, Database 
Management Systems, API Integration, Model Evaluation, Data Visualisation

Tools: Scikit-learn, TensorFlow, NLTK, Pandas, NumPy, TF-IDF Vectorizer, Jupyter Notebooks, PyCharm, Flask, GitHub

# [Data Visualization projects]( https://public.tableau.com/app/profile/santhosh.guntupalli/vizzes )

Produced diverse data visualizations across my professional tenure and academic endeavors.

Skills: Data Analysis, Visualization Design, Statistical Knowledge, Storytelling with Data, Critical Thinking, Domain Knowledge

Tools: Matplotlib, Tableau, Pandas, Python, SQL, NoSQL, Git, GitHub,

# [Real time Stock Market Analysis]( https://github.com/guntupalli09/stock_market-real_time-analysis )

Real-time stock market analysis providing live trend indicators for informed investment decisions

Skills: Data Streaming, Cloud Services, Data Processing, Data Warehousing, API Integration, Model Evaluation

Tools: Kafka, Amazon EC2, Amazon S3, Crawler, AWS Glue Datalog, Amazon Athena, GitHub, jupyter notebook

# [Snake Game With Python](assets/PythonSnakeGame.gif)

<img align="center" src="assets/PythonSnakeGame.gif" alt="santhoshguntupalli" height="200" width="400" />

Created a dynamic Snake Game using Tkinter, showcasing skills in GUI programming and event handling. Excels in problem-solving, logical thinking, and attention to detail

# [Pong Game- AI--using Python and Neat](assets/PythonPongGame-AI.gif)

<img align="center" src="assets/PythonPongGame-AI.gif" alt="santhoshguntupalli" height="200" width="400" />

Utilizing the NEAT (NeuroEvolution of Augmenting Topologies) algorithm, an AI model is trained to play Pong in Python. NEAT evolves neural networks, enhancing their structure and weights over generations. The trained AI learns to play Pong autonomously through reinforcement learning, optimizing its performance to maximize gameplay proficiency.


### <img align="center" src="assets/certificate.png" alt="santhoshguntupalli" height="50" width="60" /> Certifications
1. META Database Structures and Management with MySQL
2. META Version Control
3. META Advanced MySQL
4. Prompt Engineering For Chatgpt - Vanderblit University
5. IBM Exploratory Data Analysis for Machine Learning
6. Machine Learning Specialisation - University of Washington

## <img align="center" src="assets/career.png" alt="santhoshguntupalli" height="50" width="60" /> Work Experience



### FedEx Dataworks, Remote June 2024 - Present
### Mphasis, New York                                                                                                                  March 2024- june 2024
Position: Data Engineer

Processed and analyzed 50 petabytes of diverse streaming data using Apache Spark, Apache Flink, and Apache Kafka.
Handled 100 terabytes of data transformation into Amazon Redshift and Google BigQuery, ensuring integrity via Talend and Apache NiFi while optimizing query performance for various DBMS.

Employed Apache Hadoop, Apache Hive, and cloud-based services (AWS, GCP, Azure) for improved accessibility, reduced query latency by 40%, and managed over 1,000 data workflows securely.
Implemented robust data quality checks, security measures, CI/CD workflows, and orchestration strategies, resulting in a 30% increase in scalability and real-time system visibility.

Derived actionable insights using Python, R, and machine learning, contributing to a 15% increase in data-driven decision-making while leveraging Databricks for a 25% speed increase in big data processing.
Collaborated cross-functionally, designing APIs, leading A/B testing, and contributing significantly to machine learning/statistical model development, enhancing operational efficiency and customer satisfaction.

### LTI Mindtree, Hyderabad, India                                                     September 2019- August 2022
Position: Data Engineer

Managed 100 terabytes of diverse data utilizing Apache Spark, Kafka, and Hadoop, achieving a 35% increase in data processing efficiency.
Loaded 50 petabytes into Amazon Redshift and Google BigQuery, elevating analytics and reporting speed by 40%.

Collaborated with 15 teams to optimize data models, resulting in a 25% boost in retrieval speed and a 20% reduction in storage expenses.
Attained a 30% increase in query performance via SQL fine-tuning, indexing, and partitioning strategies.

Automated 50 data workflows, reducing manual effort by 30% and enhancing pipeline monitoring efficiency.
Oversaw 10 data warehousing solutions, increasing analytics speed by 50%, while handling 20 data streams for real-time processing, reducing processing time by 40%. Additionally, leveraged Python, R, and machine learning to develop 30 predictive models, achieving a 15% improvement in prediction accuracy.




