# Data Engineer

### Education
Master's in Management Information Systems

### Projects

1.	Content Recommendation Engine- [LINK] (https://mrs-sg-bfc2e6fa78db.herokuapp.com/)
•	Role & Contributions: Implemented ML algorithms, increasing user engagement by 30% and improving content click-through rates by 25%.

•	Outcomes: Enhanced user satisfaction and retention through efficient personalized content discovery.

•	Tools: Apache Spark, Apache Kafka, TensorFlow, PyTorch, Elasticsearch, Redis, Apache Flink.

2. Supply Chain Optimization
•	Role & Contributions: Applied predictive analytics, reducing inventory costs by 20% and improving on-time deliveries by 15%.

•	Outcomes: Enhanced supply chain efficiency by minimizing stock-outs and optimizing inventory management.

•	Tools: Apache Hadoop, Python Pandas, Apache Spark, TensorFlow, Tableau, IBM Sterling Supply Chain Suite.

3. Data Visualization projects- [link] (https://public.tableau.com/app/profile/santhosh.guntupalli/vizzes)

 ### work experience
Company 1:  Mphasis, New York                                                                                                          August 2022- September 2023
Position: Data Engineer
Roles and Responsibilities

•	Processed and analyzed over 50 petabytes of streaming data from various sources using Apache Spark, Apache Flink, and Apache Kafka.
•	Loaded and transformed approximately 100 terabytes of data into Amazon Redshift and Google BigQuery, ensuring data consistency and integrity through ETL Development leveraging Talend and Apache NiFi.
•	Optimized query performance and maintained high availability for 5 different Database Management Systems (DBMS), handling a combined workload of 500 queries per hour with systems including MySQL, PostgreSQL, MongoDB, and Amazon Redshift.
•	Improved data accessibility and reduced query latency by 40% through the utilization of Apache Hadoop and Apache Hive for distributed data processing and storage.
•	Designed and deployed cloud-based solutions across AWS, GCP, and Microsoft Azure, handling over 1,000 data workflows using services such as Amazon S3, Google Cloud Pub/Sub, Azure Event Hubs, and Azure Synapse Analytics.
•	Implemented data quality checks using tools like Talend, Apache Nifi, and Great Expectations, ensuring data accuracy, completeness.
•	Implemented data security measures utilizing Apache Ranger, AWS Key Management Service, and Azure Key Vault to encrypt sensitive data and ensure compliance with security standards.
•	Designed and implemented CI/CD workflows for data processing pipelines, ensuring automated integration, testing, and deployment of data transformations.
•	Managed orchestration, achieving a 30% increase in scalability for data processing by containerizing 10 data applications using Docker.
•	Enabled real-time visibility into system performance by implementing monitoring and logging solutions, reducing troubleshooting time by 25% for data processing bottlenecks using ELK Stack, Prometheus, and Grafana.
•	Improved overall system efficiency by 20% through performance tuning of data pipelines, resulting in a 30% reduction in processing times.
•	Derived actionable insights and built predictive models using Python, R, and machine learning libraries for enhancing overall system efficiency, contributing to a 15% increase in data-driven decision-making processes.
•	Leveraged Databricks platform to optimize big data processing, resulting in a 25% increase in processing speed and efficiency.
•	Collaborated with cross-functional teams to design, develop, and integrate APIs, enabling seamless data exchange between systems and facilitating real-time data access for internal and external stakeholders. 
•	Spearheaded A/B testing procedures, meticulously designing experiments and scrutinizing data to furnish crucial insights for informed decision-making. Leveraged statistical analysis to optimize product strategies and enhance user experience, showcasing adeptness in experiment design and hypothesis testing.
•	Contributed significantly to the development of a machine learning or statistical model, playing a key role in its initial architecture, feature engineering, and algorithm selection. Although the code underwent revisions pre-deployment, provided pivotal insights and solutions that facilitated the creation of an impactful predictive tool integrated into the production environment, bolstering operational efficiency or customer satisfaction.

Company 2: LTI Mindtree, Hyderabad, India                                                                                                 September 2019- August 2022
Position: Data Engineer
Roles and Responsibilities
•	Processed and managed over 100 terabytes of structured and unstructured data using Apache Spark, Kafka, and Hadoop, resulting in a 35% increase in data processing efficiency.
•	Loaded approximately 50 petabytes of data into data warehouses such as Amazon Redshift and Google BigQuery, contributing to a 40% improvement in analytics and reporting speed.
•	Engaged with 15 cross-functional teams to gather requirements and create data models, resulting in a 25% improvement in retrieval speed and a 20% reduction in storage costs.
•	Achieved a 30% increase in query performance by fine-tuning SQL queries, implementing indexing strategies, and partitioning techniques.
•	Implemented validation processes leading to a 15% decrease in data errors or inconsistencies, adhering to data governance best practices.
•	Automated 50 data workflows, resulting in a 30% reduction in manual effort and improved efficiency in monitoring data pipelines' health.
•	Improved database system availability by 25%, resolving 100 critical issues within a year, ensuring reliability for critical operations.
•	Oversaw 10 data warehousing solutions, delivering a 50% improvement in analytics speed to stakeholders.
•	Handled 20 data streams with Apache Kafka, AWS Kinesis, and Google Cloud Pub/Sub, enabling real-time processing, resulting in a 40% reduction in processing time.
•	Leveraged Python, R, and machine learning libraries to create 30 predictive models, contributing to a 15% increase in accuracy in predictions.

### Certifications
1. 

